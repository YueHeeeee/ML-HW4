{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, metrics\n",
    "import utils\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from linear_classifier import LinearSVM_twoclass\n",
    "\n",
    "# load the SPAM email training dataset\n",
    "\n",
    "X,y = utils.load_mat('data/spamTrain.mat')\n",
    "yy = np.ones(y.shape)\n",
    "yy[y==0] = -1\n",
    "\n",
    "val_indx = 3000\n",
    "Xval = X[val_indx:y.shape[0]]\n",
    "yval = yy[val_indx:y.shape[0]]\n",
    "\n",
    "X = X[0:val_indx]\n",
    "yy = yy[0:val_indx]\n",
    "\n",
    "# load the SPAM email test dataset\n",
    "\n",
    "test_data = scipy.io.loadmat('data/spamTest.mat')\n",
    "X_test = test_data['Xtest']\n",
    "y_test = test_data['ytest'].flatten()\n",
    "yy_test = np.ones(y_test.shape)\n",
    "yy_test[y_test == 0] = -1\n",
    "\n",
    "##################################################################################\n",
    "#  YOUR CODE HERE for training the best performing SVM for the data above.       #\n",
    "#  what should C be? What should num_iters be? Should X be scaled?               #\n",
    "#  should X be kernelized? What should the learning rate be? What should the     #\n",
    "#  number of iterations be?                                                      #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Should X be scaled? Yes\n",
    "# Should X be kernelized? Yes\n",
    "from linear_classifier import LinearSVM\n",
    "Best_accuracy = 0\n",
    "sigmas = [1,10,100]\n",
    "# choosing sigma\n",
    "for sigma in sigmas:\n",
    "    # compute the kernel (slow!)\n",
    "    K = np.array([utils.gaussian_kernel(x1,x2,sigma) for x1 in X for x2 in X]).reshape(X.shape[0],X.shape[0])\n",
    "    # scale the kernelized data matrix\n",
    "    scaler = preprocessing.StandardScaler().fit(K)\n",
    "    scaleK = scaler.transform(K)\n",
    "    # add the intercept term\n",
    "    KK = np.vstack([np.ones((scaleK.shape[0],)),scaleK.T]).T\n",
    "\n",
    "    # seperating val set\n",
    "    # compute the kernel (slow!)\n",
    "    Kval = np.array([utils.gaussian_kernel(x1,x2,sigma) for x1 in Xval for x2 in X]).reshape(Xval.shape[0],X.shape[0])\n",
    "    # scale the kernelized data matrix\n",
    "    scaler_val = preprocessing.StandardScaler().fit(Kval)\n",
    "    scaleK_val = scaler.transform(Kval)\n",
    "    # add the intercept term\n",
    "    KKval = np.vstack([np.ones((scaleK_val.shape[0],)),scaleK_val.T]).T \n",
    "\n",
    "    # seperating train set\n",
    "    # compute the kernel (slow!)\n",
    "    Ktest = np.array([utils.gaussian_kernel(x1,x2,sigma) for x1 in X_test for x2 in X]).reshape(X_test.shape[0],X.shape[0])\n",
    "    # scale the kernelized data matrix\n",
    "    scaler_test = preprocessing.StandardScaler().fit(Ktest)\n",
    "    scaleK_test = scaler.transform(Ktest)\n",
    "    # add the intercept term\n",
    "    KKtest = np.vstack([np.ones((scaleK_test.shape[0],)),scaleK_test.T]).T \n",
    "        \n",
    "    svm = LinearSVM_twoclass()     \n",
    "    svm.train(KK,yy,learning_rate=1e-4,reg=100,num_iters=1000,verbose=False,batch_size=KK.shape[0])\n",
    "    predy = svm.predict(KKval)\n",
    "    accuracy = np.mean(predy == yval)\n",
    "    print(\"Accuracy is \",accuracy, \"when sigma = \",sigma)\n",
    "    if accuracy > Best_accuracy:\n",
    "        Best_accuracy, Best_sigma = accuracy, sigma\n",
    "print(\"Best accuracy = \", Best_accuracy, \"Best sigma = \", Best_sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = Best_sigma\n",
    "# compute the kernel (slow!)\n",
    "K = np.array([utils.gaussian_kernel(x1,x2,sigma) for x1 in X for x2 in X]).reshape(X.shape[0],X.shape[0])\n",
    "# scale the kernelized data matrix\n",
    "scaler = preprocessing.StandardScaler().fit(K)\n",
    "scaleK = scaler.transform(K)\n",
    "# add the intercept term\n",
    "KK = np.vstack([np.ones((scaleK.shape[0],)),scaleK.T]).T\n",
    "\n",
    "# seperating val set\n",
    "# compute the kernel (slow!)\n",
    "Kval = np.array([utils.gaussian_kernel(x1,x2,sigma) for x1 in Xval for x2 in X]).reshape(Xval.shape[0],X.shape[0])\n",
    "# scale the kernelized data matrix\n",
    "scaler_val = preprocessing.StandardScaler().fit(Kval)\n",
    "scaleK_val = scaler.transform(Kval)\n",
    "# add the intercept term\n",
    "KKval = np.vstack([np.ones((scaleK_val.shape[0],)),scaleK_val.T]).T \n",
    "\n",
    "# seperating train set\n",
    "# compute the kernel (slow!)\n",
    "Ktest = np.array([utils.gaussian_kernel(x1,x2,sigma) for x1 in X_test for x2 in X]).reshape(X_test.shape[0],X.shape[0])\n",
    "# scale the kernelized data matrix\n",
    "scaler_test = preprocessing.StandardScaler().fit(Ktest)\n",
    "scaleK_test = scaler.transform(Ktest)\n",
    "# add the intercept term\n",
    "KKtest = np.vstack([np.ones((scaleK_test.shape[0],)),scaleK_test.T]).T \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.599 when C =  0.01\n",
      "Accuracy is  0.632 when C =  0.03\n",
      "Accuracy is  0.698 when C =  0.1\n",
      "Accuracy is  0.853 when C =  0.3\n",
      "Accuracy is  0.922 when C =  1\n",
      "Accuracy is  0.934 when C =  3\n",
      "Accuracy is  0.959 when C =  10\n",
      "Accuracy is  0.963 when C =  30\n",
      "Accuracy is  0.976 when C =  100\n",
      "Best accuracy =  0.976 Best C =  100\n"
     ]
    }
   ],
   "source": [
    "Best_accuracy, Best_C = 0, 0\n",
    "# what should C be?\n",
    "Cvals = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "for C in Cvals:\n",
    "    svm = LinearSVM_twoclass()     \n",
    "    svm.train(KK,yy,learning_rate=1e-4,reg=C,num_iters=1000,verbose=False,batch_size=KK.shape[0])\n",
    "    predy = svm.predict(KKval)\n",
    "    accuracy = np.mean(predy == yval)\n",
    "    print(\"Accuracy is \",accuracy, \"when C = \",C)\n",
    "    if accuracy > Best_accuracy:\n",
    "        Best_accuracy, Best_C = accuracy, C\n",
    "print(\"Best accuracy = \", Best_accuracy, \"Best C = \", Best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.708 when learning rate =  0.01\n",
      "Accuracy is  0.967 when learning rate =  0.001\n",
      "Accuracy is  0.975 when learning rate =  0.0001\n",
      "Accuracy is  0.958 when learning rate =  1e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy =  0.975 Best learning rate =  0.0001\n"
     ]
    }
   ],
   "source": [
    "# What should the learning rate be?\n",
    "Best_accuracy, Best_lr = 0, 0\n",
    "color = ['red','green','blue','yellow']\n",
    "count = 0\n",
    "# Best_C =  100\n",
    "learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "fig = plt.figure()\n",
    "for lr in learning_rates:\n",
    "    svm = LinearSVM_twoclass()\n",
    "    J_theta = svm.train(KK,yy,learning_rate=lr,reg=Best_C,num_iters=1000,verbose=False,batch_size=KK.shape[0])\n",
    "    predy = svm.predict(KKval)\n",
    "    accuracy = np.mean(predy == yval)\n",
    "    print(\"Accuracy is \",accuracy, \"when learning rate = \",lr)\n",
    "    if accuracy > Best_accuracy:\n",
    "        Best_accuracy, Best_lr = accuracy,lr\n",
    "    J_reverse = J_theta.sort(reverse = True)\n",
    "    plt.plot(range(len(J_reverse)),J_reverse)\n",
    "    count += 1\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('J theta')\n",
    "plt.legend([str(i) for i in learning_rates])\n",
    "plt.show()\n",
    "print(\"Best accuracy = \", Best_accuracy, \"Best learning rate = \", Best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20a80127978>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# J_reverse = J_theta.sort(reverse = True)\n",
    "# len(J_reverse)\n",
    "plt.plot(range(len(J_theta)),J_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698 [100.13046279031758, 5241.139282415243, 30180.461151856784, 10659.511732242421, 22769.393470041723, 15967.367351834777, 15557.40819435992, 21048.685593841346, 8796.373517591823, 25235.930328221555, 3492.7850970941195, 25602.71940123964, 2619.9064356803437, 24187.76365606151, 3487.1632625224825, 24042.095995183747, 3195.5367468417317, 22982.507411858252, 3796.545193865064, 22519.72318756335, 3797.6259992821197, 21821.576653268046, 4002.74367737703, 21241.84941518567, 4186.863729262715, 20686.947515940723, 4333.320078715399, 20162.484015967068, 4477.690504678104, 19538.52249306005, 4633.755944930908, 18983.55540691974, 4638.448477910412, 18536.489885027077, 4618.887108187676, 17937.649942631542, 4806.801386730306, 17523.21980645987, 4913.746072636885, 17131.935624910715, 4942.0648305636205, 16688.090689551176, 5108.208688568523, 16296.940969127812, 5125.132179264311, 15804.321266096498, 5267.28244587135, 15437.803658232835, 5253.2401461596355, 15060.063180930332, 5223.920469801366, 14419.303143891262, 5479.7543063623025, 14420.817441073412, 5259.754475125082, 13695.857787195613, 5341.059299869501, 13436.321405770395, 5205.020989134954, 12975.171403820925, 5304.248811328144, 12758.72739569918, 5165.8717984791565, 12579.059786844166, 5074.36698212748, 12375.12078339545, 5067.973138962138, 12093.628445971259, 5102.125388744496, 11879.826979370942, 5102.252986000816, 11613.791287824524, 5139.176704153894, 11340.10996319022, 5043.895734889226, 11065.650405294618, 5095.887763223999, 10880.88638128452, 5053.323228260799, 10559.777682743685, 5123.364485117799, 10388.595975054986, 4950.053446412574, 10206.219182529949, 4921.298888892621, 9971.25772258242, 4909.325525542079, 9813.52406726551, 4928.220447352982, 9650.49809113429, 4956.383934465303, 9520.408134083656, 4910.056380983381, 9406.90252536835, 4860.09140033671, 9236.303184436458, 4869.899613554589, 9108.393801326538, 4807.687014199004, 8836.515149903293, 4680.321281706249, 8522.571120665105, 4816.354530952752, 8505.560452685995, 4641.199967690896, 8158.362009173984, 4576.558148421484, 7994.6967382758, 4530.850137523532, 7872.619296334309, 4479.633404505356, 7684.274291618912, 4477.981422766506, 7555.180783537091, 4459.760433485814, 7334.010372471498, 4459.345244383121, 7243.992295218881, 4461.705795099696, 7141.831444785758, 4383.35725663112, 7010.1047925281, 4323.530315528799, 6807.805402609154, 4272.698234128899, 6707.1879119948135, 4224.81769716574, 6565.33468447207, 4231.986729893829, 6437.402326674369, 4271.570939797678, 6340.972638529246, 4277.208929503591, 6255.81235958903, 4223.669107265012, 6094.298706745396, 4213.096913498644, 5986.580408478728, 4164.527674269426, 5853.208277880737, 4189.332562812101, 5772.494266459778, 4168.946653459139, 5690.71233366877, 4085.766562745305, 5376.41907833863, 4194.456591452138, 5484.598557776271, 4081.4094981498674, 5145.187126602241, 4285.328322524859, 5360.455351715058, 4060.625387761084, 5016.607404460293, 4212.974758601361, 5051.828215295777, 4151.384190136239, 4907.811135469413, 4153.73200227246, 4842.813894752185, 4150.733643917002, 4729.63824131607, 3984.9848540258604, 4488.661404304441, 3747.332229082962, 4176.166715491132, 3360.5490456210773, 3347.1896413336653, 2254.211583129733, 1645.8313632518903, 1270.4102684465104, 1180.2318080505595, 1136.641991325073, 1104.1692897020396, 1074.704058961243, 1049.704521698184, 1037.5739617317872, 1017.2140504358355, 997.4651816887695, 986.8339704807981, 962.8624331405312, 950.0682046428252, 937.778044788076, 925.6708837793586, 913.759647147845, 902.1343969490249, 891.3957290077143, 880.9887661315673, 870.8387356112991, 861.2060929989455, 851.6366916101962, 842.1221985887354, 832.8075220892698, 823.5308391013427, 814.3510572946766, 805.5129079680383, 796.9744791000272, 788.6381486371539, 780.5942205592219, 772.6997612505485, 765.218703823713, 757.4899822440095, 750.120203976495, 742.9146568466466, 735.88181783231, 729.1725048794539, 722.5500162887624, 715.9341374829544, 709.4575281629708, 703.1958866708658, 697.4733480493069, 691.5872253495357, 685.8127894771782, 680.3723682241824, 674.9319832406015, 669.5017291500966, 664.3170262109792, 659.5056830878079, 655.010494903684, 650.706474700218, 646.4024831901722, 642.0985203733554, 637.794586249576, 633.5525770855371, 629.8026559835944, 627.6577140256207, 624.6695281771142, 620.0405006839975, 620.0734439547939, 615.5824194549969, 615.2304304263965, 609.0154408195102, 611.3923276338293, 604.9464167247934, 603.9934686372084, 597.7422539570498, 596.1160171877387, 592.1680605001714, 588.0657900904175, 584.2326525222878, 582.3670333492356, 579.9204672339151, 577.261814606543, 576.681962375305, 570.847807451175, 570.3008296298422, 565.6314213022683, 565.6060011060738, 563.9219228585522, 565.2194554235818, 571.5048973931739, 568.9019560958376, 569.4343508772191, 569.3079715019287, 583.6673984811285, 582.2086040777873, 590.0014034210551, 589.5073535081046, 604.9116613565565, 579.4905626936649, 593.4342130977703, 574.9241196984084, 589.0371137322661, 570.3664098481212, 587.5103782584905, 566.9024381631416, 582.0412682543135, 559.469225143412, 576.3118023425462, 556.2940514169895, 575.4333714955405, 563.6624362018913, 577.8698305027249, 558.295443584783, 574.5620441991234, 553.1812144438899, 568.8284299309979, 550.3446148209953, 563.0948824541246, 547.5080626757633, 557.4047205944574, 543.8762296208457, 552.5806700014454, 540.869890650741, 549.8178910933489, 532.6521646030332, 547.0604130081265, 533.3556104757017, 540.7085765285236, 531.427101921097, 534.4837694239378, 517.7107892326125, 515.3568238373415, 488.4394830087157, 484.055568121555, 475.3204753428602, 467.25508665093406, 464.24817207491384, 461.17152838408657, 462.07638139097963, 459.6130829256083, 457.5408062452892, 453.7600930743248, 456.18083799422413, 452.25790949754224, 451.95548737347906, 448.13390257801683, 448.3082621320152, 445.06109274193807, 444.6738343419488, 440.78787459859956, 439.7399359197884, 437.16532669051054, 435.9456499153185, 433.9842897889678, 432.44027063033275, 430.3711063504854, 429.6535941483799, 426.69916553218525, 426.3895700726099, 423.3045683706439, 422.8899759618083, 420.24213639118653, 419.75194121445793, 417.17974549602764, 416.62349946547965, 413.8378299810711, 411.7899371290268, 409.8001767215052, 407.4350547785051, 405.9356761630327, 404.03934341459376, 402.4609004763142, 400.88499860843285, 399.3081470071545, 397.72991506860023, 396.17988561578716, 394.5848791950174, 393.04821792093986, 391.81586232906966, 390.7315150148385, 389.7280030008236, 388.24546782785336, 387.86895323320766, 385.3460933101355, 385.45768464777353, 382.21631617144305, 381.75517957324047, 379.3385982885528, 379.9566532128499, 377.05301958799413, 379.0149330411336, 374.6967157109858, 375.376794928952, 372.34044752402434, 371.7686544339823, 368.9847344236873, 369.1441253039033, 366.02994831463457, 366.13316844892506, 363.0752017898339, 363.12225155253725, 360.12049484875615, 360.11137461420833, 357.1779838550389, 357.7260686640075, 354.2322015988065, 354.72656783222845, 351.286458798601, 351.74373910754406, 347.65916598080844, 347.0945558149235, 344.4093061517174, 342.55234023703775, 340.4781034251276, 338.97845262824757, 337.7778205754425, 336.17017407706635, 334.8385681402298, 333.68731501608204, 332.54922208209223, 331.4243181788851, 330.26774083343196, 329.2200286020813, 328.11470691990377, 327.04505345199937, 325.9754071151062, 324.9057679091768, 323.8361358341635, 322.76651089001876, 321.6994363556229, 320.6365418859056, 319.57170976505006, 318.5229862671316, 317.44427667031687, 316.56886228885725, 315.3243035946549, 314.27016108521417, 313.2161627664801, 312.1683580859638, 311.13483997876307, 310.22352699368895, 309.02642933316514, 307.98629739066894, 306.98416967445866, 306.0717914531355, 304.9864159018024, 304.06563688950087, 302.8647755084926, 302.0595094594561, 300.76231958029473, 299.72135928489746, 298.6869785869574, 297.65243724965006, 296.91816070071604, 296.4171218966462, 294.7984292214987, 293.7428529555132, 292.8215658637681, 292.4370543868335, 290.8925794582209, 290.3396551038715, 288.9366057062061, 288.3911415354709, 286.98065800888713, 286.4475433007739, 284.9473193071099, 284.5986525071992, 283.170384390214, 282.49845170094056, 281.1370969546406, 280.6535336422791, 279.1860311532283, 278.7791637676117, 277.2349911102878, 276.9048191400258, 275.2863163255758, 274.9748023131023, 273.43925673460734, 273.0448109431276, 271.603957445935, 271.5229975903825, 270.05174423899757, 270.1318119252645, 268.2547354677041, 267.74501025556464, 266.14581882021207, 265.48513525649093, 264.4500967747433, 263.9656801546706, 262.6370857516057, 261.9489536546881, 260.96490567333547, 260.54246454803166, 259.05503490201, 258.3996652789561, 257.58237318769613, 258.1542290479275, 257.80736808495624, 260.12282800606255, 256.4997974457445, 258.062392954297, 254.60521262868517, 256.5965386464485, 253.30430205156512, 255.11369666039067, 251.44011486959096, 252.8831890598223, 249.75851580544528, 251.23873609028266, 248.0769390387258, 249.59430517045493, 246.4091859901455, 245.84536821066192, 245.48554287330805, 247.14912071310206, 242.90047538493215, 241.66386173169755, 240.33579439206926, 239.62809563002799, 239.08080647174478, 237.94807715449346, 237.50304677705316, 237.2481043138925, 236.09853034016058, 234.9358027193842, 234.1287919600513, 232.77656910398196, 233.15691434292012, 233.61817534298572, 231.8315355503657, 231.36780715574807, 230.0006264709879, 230.1081236472677, 228.24257011435836, 226.86111793272556, 226.6399646524882, 225.32992597379356, 225.0596179931226, 225.14857976658487, 223.41916701641944, 221.88037662752245, 222.6714439457848, 226.49278274350763, 223.48916252158452, 232.52710745854367, 232.51930593091987, 246.78786970348872, 259.2909210183953, 266.42498169833897, 311.27900941457386, 496.3128853370746, 1871.6654019530192, 6640.6314894330735, 11222.316299386997, 4342.238280208756, 10114.194282589715, 4817.35122347604, 10234.04387656841, 4464.684511857176, 9775.465618035953, 4654.83660263702, 9726.717209654918, 4443.1023996919075, 9368.792837410638, 4423.616730529421, 9091.011410860132, 4444.330583944389, 9018.45341751337, 4333.5225838287, 8776.956268519565, 4347.379412382661, 8788.663531275866, 4166.160002870811, 8388.90143895582, 4097.9473753470675, 8088.440187470844, 4072.9855229799555, 8028.831083093291, 3977.5322731889787, 7757.9991068249155, 4039.673830182939, 7725.762195947308, 3974.142178753122, 7578.759375792087, 3947.7475642921127, 7417.405255707539, 3913.5871649928395, 7095.297503135331, 3874.8201572675925, 6966.910290039642, 3691.0343730800773, 6795.136711963601, 3624.1587467617933, 6687.6276869072035, 3560.979124209725, 6490.969576769931, 3489.132079119289, 6244.6019859523185, 3497.596684060631, 6145.335713357498, 3421.0223353835077, 5984.974845493533, 3454.894600027407, 5953.774875679518, 3420.401765385839, 5738.367234186199, 3468.226612546331, 5686.444231511133, 3454.392661146303, 5582.546272070631, 3492.9356383730233, 5490.999767743004, 3419.455786537812, 5377.602866335216, 3443.7798573721334, 5287.272412625451, 3294.3292715959883, 5077.726535993315, 3300.922520561907, 4984.414031031622, 3125.424102147387, 4697.622007930653, 2956.919980155943, 4440.046222353468, 2744.7442392962503, 3922.428069945659, 2573.0875742180388, 3611.287167901763, 2295.5231632121445, 2885.757675195749, 1702.4045069745966, 1328.0283536945499, 699.6617145816325, 683.3727567653615, 668.9605386112376, 654.3530516746184, 635.1374741970915, 625.9362505813135, 607.2337934048483, 597.0584893997773, 587.3230111487317, 577.609462472851, 568.2749501404236, 559.5133666390404, 551.4350166741897, 543.8148935456157, 536.2495596175409, 528.7954628724303, 521.5503496239261, 514.2986713845476, 507.2737026647342, 500.43093073715994, 493.59681866740993, 486.8645900704948, 480.4203677582407, 474.0300324193828, 467.83384221853197, 461.93670753391973, 456.0757243716389, 450.5265319868049, 445.39114545992084, 440.8147157462103, 436.43223409863845, 432.2818341376278, 428.1558838208608, 424.13999818963106, 421.21052274310813, 418.5344091745866, 413.16210034990706, 410.0501392189624, 406.9900130295279, 403.9343838675099, 400.9604512884273, 398.0820452878536, 396.02730455082013, 393.16440340903216, 390.7819387332269, 388.4960819781258, 386.2533336850745, 384.03985424443425, 381.8849949110288, 379.7689017298839, 377.82958342175937, 375.87478136521366, 374.30073356119124, 372.4601216778006, 371.0537226802716, 369.5673801021285, 368.0674696168279, 366.13440320249794, 364.7256539773731, 363.2368757435764, 361.32563575807325, 359.930538688669, 358.45357288771476, 357.11734306990843, 355.7359107214633, 354.4239982232663, 353.1297584250976, 351.8101785392114, 350.61461407847474, 349.41772395996406, 348.2208418207075, 347.0338990293546, 345.83876505086397, 344.6419067712937, 343.44505647076534, 342.2577468814791, 341.0630433790702, 339.8662169375914, 338.66939847494217, 337.5290308623415, 336.4122494909826, 335.30899387711986, 334.20809978542985, 333.11322903095515, 332.11262934354215, 331.2279855394313, 329.9630498962407, 328.78489241555195, 327.94577783269443, 326.9537488882541, 325.64431186502225, 324.8377556412416, 323.81311203304574, 322.50369594735804, 321.75711141879486, 320.7749896893368, 319.7535043512402, 318.591069865718, 317.58786098095015, 316.6533818496591, 316.04755923049623, 314.8078101717358, 314.02324368395483, 312.64573919815734, 311.7809155191578, 310.8379290198343, 309.90146846474323, 309.0301431843553, 308.08280450809525, 307.16162329455415, 306.27505535655644, 305.32773504751793, 304.44260864212936, 303.6152694236062, 302.74788399768886, 301.8134310138954, 300.96417239927405, 300.0116165681941, 299.1804846439439, 298.2098260861832, 297.39682073138005, 296.4080595675437, 295.61689942769016, 294.74030007459453, 293.712783528948, 292.9385805311826, 291.9346744232317, 291.2811479241792, 290.13094892503256, 289.2209789512626, 288.34512467735186, 287.49451691892574, 286.5748462886109, 285.7904470242807, 285.1517678142744, 283.9810218570431, 283.0965281499515, 282.2708794608582, 281.40010192363764, 280.4805533763941, 279.74685050481105, 278.78607176226546, 277.95406873799504, 277.17351827776736, 276.3804157321097, 275.5863728969202, 274.8064806763349, 274.0127514580134, 273.2190638031385, 272.4575313110933, 271.6881440437775, 270.8803265883961, 270.0725145184554, 269.33399710669084, 268.5673626318572, 267.7297407669448, 266.94803903438276, 266.1754213585676, 265.3955165788471, 264.6138304077536, 263.8377743625568, 263.06133908635707, 262.27966847642097, 261.5092712746793, 261.1236431647556, 260.07300839027585, 259.51596624874634, 259.0112643190841, 257.96332163095065, 257.46409076016823, 256.34732035818655, 256.03958953347853, 255.45844870644964, 254.43458582622114, 253.74090121057296, 252.75877641096116, 252.16887188372425, 251.58550568078084, 251.09979676989454, 250.2034864602573, 249.69828205381478, 248.9434078392715, 248.23487424456937, 247.22657668216618, 246.6530035399063, 246.02002389351793, 245.42619522024322, 244.51002803995777, 243.99822424382444, 243.1984161313459, 242.67388641331112, 241.80226908246058, 241.2459519857218, 240.50375150711068, 239.92165066002482, 239.09889101339306, 238.6043616896463, 238.04887555743323, 237.20618266047387, 236.37034244099607, 235.78634803385305, 235.011030361535, 234.58942206055755, 234.3528796646605, 233.59449536481017, 232.87721259003715, 232.40173086847798, 231.42901499530518, 230.56108171742545, 230.21107010508922, 229.58407625500067, 228.91300603877747, 228.50101756467626, 227.37648548642926, 226.88467775643142, 226.1853110442532, 225.69415109324848, 224.76469198534352, 224.00145057824938, 223.86398719315207, 223.0710349644676, 222.15930202583095, 221.62764707882604, 220.98952236614434, 220.18427752626766, 219.83122995441622, 218.9938390470634, 218.42490453408217, 217.6091926991794, 217.2427168719035, 216.22456413832523, 216.06296861999323, 215.1054051706381, 214.59396965249175, 213.7972631900053, 213.3744760119911, 212.48913835571398, 212.1549989267879, 211.18103066753736, 210.93553839665933, 209.87294012524896, 209.7160944213826, 208.57466602408994, 207.8553809730199, 207.8025701905294, 207.56863507448335, 205.82852102735993, 205.50004174436032, 205.10258265238616, 204.95570603333653, 203.36118282086875, 202.9139252308414, 202.7469947797723, 202.60673961064444, 200.78994354618956, 200.10805315568635, 199.76371656458872, 200.23039441190787, 198.29628396459046, 197.70005020250053, 197.42266607927795, 197.62155399909142, 195.84633700953657, 195.180812344442, 194.62882761857037, 194.35839057854216, 194.94361143461816, 193.83418782857444, 193.02034576191647, 191.5646155942516, 191.14411970518861, 190.60969864895893, 190.28086250292372, 189.18091865716505, 188.62953678695783, 188.31354152149999, 187.89849430745983, 186.7211019747457, 186.09716689699175, 186.05303657954505, 185.3403528786773, 184.3741269443408, 184.1619859565643, 183.13118194537265, 182.98363496121746, 181.9064335019007, 181.3723891629656, 181.0147143447347, 180.48270020629067, 179.44820959724441, 178.85397997316323, 178.72946409729707, 178.1885965620666, 177.87522550159375, 177.04284874288098, 176.74450571997292, 175.81626234952228, 175.6138013341198, 174.58978554976932, 173.61200176312266, 172.9762537597495, 172.3827471105334, 171.83950049312318, 171.8159358848395, 170.83179955342618, 170.5367108735009, 169.82411295477422, 169.2575020133139, 168.90504576333504, 168.9022110590376, 168.05013681545753, 169.13442579147343, 170.91690632160152, 173.14026425207584, 173.32901232096785, 172.75556104101992, 171.19715325552525, 170.69569183993315, 170.7690657456787, 171.45950605724408, 169.21710031752784, 170.59442530245394, 167.6729246018812, 169.09594465518467, 166.7649530991411, 167.5989715543044, 163.07413069779042, 166.30387417001396, 162.05154671315324, 161.84918860498976, 159.23949102177588, 157.90692337760194, 156.37357650872045, 155.90673696244627, 155.1618230507925, 154.8073296984048, 153.9997558861344, 153.4292737960571, 152.85879550918747, 152.28832102550007, 151.7178503449695, 151.14860258584, 150.58618857395237, 150.1772690636266, 149.78315354147034, 148.89301587633855, 148.31936085974934, 147.74768131335793, 147.39742524320314, 147.0665634188784, 146.3956766625253, 146.0415563681701, 145.42054314561378, 145.06863069625888, 144.44542262307957, 144.09571800396293, 143.47031509474965, 143.1228182911091, 142.49878032203637, 142.3281368337317, 141.64385480007263, 141.2767183733104, 140.57844959170862, 140.4730071098779, 140.33085189759478, 143.87774395603444, 144.66036780381017, 149.20853926267657, 150.41150247382845, 145.72820889302696, 145.4179895828392, 144.99618410468187, 143.9377232408622, 144.28389246823667, 143.96328257887978, 144.55414846742357, 142.78137676265592, 143.65668227601182, 140.33809672707704, 141.51957673014851, 139.12334829792078, 141.81003563530533, 138.87346309012034, 143.0517766843126, 144.09929881307355, 144.57881842654055, 144.13522415519662, 144.61225069567894, 147.21610709846522, 178.7888270962034, 226.32539699548317, 294.97575522619735, 846.445831780383, 1867.8686448875735, 5121.579729957392, 6335.973673535007, 9926.568503691487, 4104.686564326989, 8242.410516249663, 4884.002110599194, 8994.950065212877, 4266.039438306026, 8114.213095033608, 4517.102113172627, 8314.580492808247, 4196.929049966614, 7730.614541205828]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-65fadd75c7d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mBest_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBest_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mJ_reverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJ_theta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ_reverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mJ_reverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "svm = LinearSVM_twoclass()\n",
    "J_theta = svm.train(KK,yy,learning_rate=1e-2,reg=Best_C,num_iters=1000,verbose=False,batch_size=KK.shape[0])\n",
    "predy = svm.predict(KKval)\n",
    "accuracy = np.mean(predy == yval)\n",
    "print(accuracy,J_theta)\n",
    "if accuracy > Best_accuracy:\n",
    "    Best_accuracy, Best_lr = accuracy,lr\n",
    "J_reverse = J_theta.sort(reverse = True)\n",
    "plt.plot(range(len(J_reverse)),J_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 2000: loss 99.937522\n",
      "iteration 100 / 2000: loss 67.396680\n",
      "iteration 200 / 2000: loss 49.893368\n",
      "iteration 300 / 2000: loss 14.022788\n",
      "iteration 400 / 2000: loss 14.110224\n",
      "iteration 500 / 2000: loss 37.372113\n",
      "iteration 600 / 2000: loss 10.804756\n",
      "iteration 700 / 2000: loss 10.141990\n",
      "iteration 800 / 2000: loss 9.100913\n",
      "iteration 900 / 2000: loss 34.392209\n",
      "iteration 1000 / 2000: loss 8.268447\n",
      "iteration 1100 / 2000: loss 7.589044\n",
      "iteration 1200 / 2000: loss 8.605159\n",
      "iteration 1300 / 2000: loss 7.219641\n",
      "iteration 1400 / 2000: loss 6.794903\n",
      "iteration 1500 / 2000: loss 7.059027\n",
      "iteration 1600 / 2000: loss 6.517537\n",
      "iteration 1700 / 2000: loss 6.709078\n",
      "iteration 1800 / 2000: loss 6.157251\n",
      "iteration 1900 / 2000: loss 7.479385\n",
      "Accuracy is  0.977 when number of iteration =  2000\n",
      "iteration 0 / 5000: loss 100.091277\n",
      "iteration 100 / 5000: loss 67.570644\n",
      "iteration 200 / 5000: loss 49.280568\n",
      "iteration 300 / 5000: loss 14.023691\n",
      "iteration 400 / 5000: loss 14.320165\n",
      "iteration 500 / 5000: loss 44.650569\n",
      "iteration 600 / 5000: loss 10.499012\n",
      "iteration 700 / 5000: loss 10.137939\n",
      "iteration 800 / 5000: loss 9.067875\n",
      "iteration 900 / 5000: loss 10.443340\n",
      "iteration 1000 / 5000: loss 8.120768\n",
      "iteration 1100 / 5000: loss 7.582928\n",
      "iteration 1200 / 5000: loss 9.375564\n",
      "iteration 1300 / 5000: loss 7.234633\n",
      "iteration 1400 / 5000: loss 6.787409\n",
      "iteration 1500 / 5000: loss 7.044427\n",
      "iteration 1600 / 5000: loss 6.465832\n",
      "iteration 1700 / 5000: loss 6.790449\n",
      "iteration 1800 / 5000: loss 6.193693\n",
      "iteration 1900 / 5000: loss 6.402464\n",
      "iteration 2000 / 5000: loss 5.847182\n",
      "iteration 2100 / 5000: loss 6.853637\n",
      "iteration 2200 / 5000: loss 5.573222\n",
      "iteration 2300 / 5000: loss 6.395732\n",
      "iteration 2400 / 5000: loss 5.323871\n",
      "iteration 2500 / 5000: loss 5.711269\n",
      "iteration 2600 / 5000: loss 5.096135\n",
      "iteration 2700 / 5000: loss 5.158740\n",
      "iteration 2800 / 5000: loss 27.425935\n",
      "iteration 2900 / 5000: loss 4.874640\n",
      "iteration 3000 / 5000: loss 4.896412\n",
      "iteration 3100 / 5000: loss 4.786462\n",
      "iteration 3200 / 5000: loss 4.696697\n",
      "iteration 3300 / 5000: loss 4.595935\n",
      "iteration 3400 / 5000: loss 4.386269\n",
      "iteration 3500 / 5000: loss 4.467503\n",
      "iteration 3600 / 5000: loss 5.404485\n",
      "iteration 3700 / 5000: loss 4.212308\n",
      "iteration 3800 / 5000: loss 4.264656\n",
      "iteration 3900 / 5000: loss 4.218378\n",
      "iteration 4000 / 5000: loss 4.154448\n",
      "iteration 4100 / 5000: loss 23.651329\n",
      "iteration 4200 / 5000: loss 3.916110\n",
      "iteration 4300 / 5000: loss 3.767552\n",
      "iteration 4400 / 5000: loss 3.979183\n",
      "iteration 4500 / 5000: loss 3.823397\n",
      "iteration 4600 / 5000: loss 3.599456\n",
      "iteration 4700 / 5000: loss 35.924348\n",
      "iteration 4800 / 5000: loss 3.590782\n",
      "iteration 4900 / 5000: loss 3.483329\n",
      "Accuracy is  0.866 when number of iteration =  5000\n",
      "iteration 0 / 10000: loss 99.399195\n",
      "iteration 100 / 10000: loss 67.259270\n",
      "iteration 200 / 10000: loss 49.414985\n",
      "iteration 300 / 10000: loss 14.020220\n",
      "iteration 400 / 10000: loss 14.183975\n",
      "iteration 500 / 10000: loss 45.811763\n",
      "iteration 600 / 10000: loss 10.472504\n",
      "iteration 700 / 10000: loss 10.194982\n",
      "iteration 800 / 10000: loss 9.022972\n",
      "iteration 900 / 10000: loss 30.157146\n",
      "iteration 1000 / 10000: loss 8.155467\n",
      "iteration 1100 / 10000: loss 7.699413\n",
      "iteration 1200 / 10000: loss 9.437535\n",
      "iteration 1300 / 10000: loss 7.239520\n",
      "iteration 1400 / 10000: loss 6.783221\n",
      "iteration 1500 / 10000: loss 7.191106\n",
      "iteration 1600 / 10000: loss 6.491305\n",
      "iteration 1700 / 10000: loss 7.706488\n",
      "iteration 1800 / 10000: loss 6.214254\n",
      "iteration 1900 / 10000: loss 7.246635\n",
      "iteration 2000 / 10000: loss 5.880506\n",
      "iteration 2100 / 10000: loss 11.424268\n",
      "iteration 2200 / 10000: loss 5.615537\n",
      "iteration 2300 / 10000: loss 7.242126\n",
      "iteration 2400 / 10000: loss 5.364826\n",
      "iteration 2500 / 10000: loss 17.598911\n",
      "iteration 2600 / 10000: loss 5.148084\n",
      "iteration 2700 / 10000: loss 5.275647\n",
      "iteration 2800 / 10000: loss 5.038059\n",
      "iteration 2900 / 10000: loss 4.933493\n",
      "iteration 3000 / 10000: loss 4.920854\n",
      "iteration 3100 / 10000: loss 4.837892\n",
      "iteration 3200 / 10000: loss 4.687145\n",
      "iteration 3300 / 10000: loss 4.508029\n",
      "iteration 3400 / 10000: loss 4.581641\n",
      "iteration 3500 / 10000: loss 4.480331\n",
      "iteration 3600 / 10000: loss 4.422199\n",
      "iteration 3700 / 10000: loss 4.184985\n",
      "iteration 3800 / 10000: loss 4.318940\n",
      "iteration 3900 / 10000: loss 4.192111\n",
      "iteration 4000 / 10000: loss 4.153027\n",
      "iteration 4100 / 10000: loss 3.855450\n",
      "iteration 4200 / 10000: loss 25.706006\n",
      "iteration 4300 / 10000: loss 3.831354\n",
      "iteration 4400 / 10000: loss 3.797737\n",
      "iteration 4500 / 10000: loss 3.788925\n",
      "iteration 4600 / 10000: loss 3.594147\n",
      "iteration 4700 / 10000: loss 4.615938\n",
      "iteration 4800 / 10000: loss 3.564847\n",
      "iteration 4900 / 10000: loss 3.477496\n",
      "iteration 5000 / 10000: loss 27.321983\n",
      "iteration 5100 / 10000: loss 3.449385\n",
      "iteration 5200 / 10000: loss 3.360795\n",
      "iteration 5300 / 10000: loss 4.517795\n",
      "iteration 5400 / 10000: loss 3.314532\n",
      "iteration 5500 / 10000: loss 3.318895\n",
      "iteration 5600 / 10000: loss 3.324362\n",
      "iteration 5700 / 10000: loss 3.214571\n",
      "iteration 5800 / 10000: loss 3.561295\n",
      "iteration 5900 / 10000: loss 3.120804\n",
      "iteration 6000 / 10000: loss 20.350253\n",
      "iteration 6100 / 10000: loss 3.118218\n",
      "iteration 6200 / 10000: loss 3.198378\n",
      "iteration 6300 / 10000: loss 3.090834\n",
      "iteration 6400 / 10000: loss 2.987840\n",
      "iteration 6500 / 10000: loss 3.118570\n",
      "iteration 6600 / 10000: loss 2.975540\n",
      "iteration 6700 / 10000: loss 3.104756\n",
      "iteration 6800 / 10000: loss 2.898097\n",
      "iteration 6900 / 10000: loss 3.065174\n",
      "iteration 7000 / 10000: loss 2.887403\n",
      "iteration 7100 / 10000: loss 2.836569\n",
      "iteration 7200 / 10000: loss 3.045606\n",
      "iteration 7300 / 10000: loss 2.842348\n",
      "iteration 7400 / 10000: loss 2.774664\n",
      "iteration 7500 / 10000: loss 2.769020\n",
      "iteration 7600 / 10000: loss 2.948098\n",
      "iteration 7700 / 10000: loss 2.713018\n",
      "iteration 7800 / 10000: loss 2.803000\n",
      "iteration 7900 / 10000: loss 3.936709\n",
      "iteration 8000 / 10000: loss 2.664738\n",
      "iteration 8100 / 10000: loss 2.830952\n",
      "iteration 8200 / 10000: loss 2.707466\n",
      "iteration 8300 / 10000: loss 2.602731\n",
      "iteration 8400 / 10000: loss 2.604599\n",
      "iteration 8500 / 10000: loss 13.218091\n",
      "iteration 8600 / 10000: loss 2.569442\n",
      "iteration 8700 / 10000: loss 2.784636\n",
      "iteration 8800 / 10000: loss 2.531359\n",
      "iteration 8900 / 10000: loss 5.612431\n",
      "iteration 9000 / 10000: loss 2.499624\n",
      "iteration 9100 / 10000: loss 2.520147\n",
      "iteration 9200 / 10000: loss 2.847872\n",
      "iteration 9300 / 10000: loss 2.463567\n",
      "iteration 9400 / 10000: loss 2.451958\n",
      "iteration 9500 / 10000: loss 2.687565\n",
      "iteration 9600 / 10000: loss 2.395653\n",
      "iteration 9700 / 10000: loss 2.548256\n",
      "iteration 9800 / 10000: loss 2.367028\n",
      "iteration 9900 / 10000: loss 2.506957\n",
      "Accuracy is  0.978 when number of iteration =  10000\n",
      "Best accuracy =  0.978 Best iteration number =  10000\n"
     ]
    }
   ],
   "source": [
    "# What should the number of iterations be? \n",
    "Best_accuracy, Best_ni = 0, 0\n",
    "num_iters = [2000, 5000, 10000]\n",
    "for ni in num_iters:\n",
    "    svm = LinearSVM_twoclass()\n",
    "    J_theta = svm.train(KK,yy,learning_rate=Best_lr,reg=Best_C,num_iters=ni,verbose=True,batch_size=KK.shape[0])\n",
    "    predy = svm.predict(KKval)\n",
    "    accuracy = np.mean(predy == yval)\n",
    "    print(\"Accuracy is \",accuracy, \"when number of iteration = \",ni)\n",
    "    if accuracy > Best_accuracy:\n",
    "        Best_accuracy, Best_ni = accuracy,ni\n",
    "print(\"Best accuracy = \", Best_accuracy, \"Best iteration number = \", Best_ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 10000: loss 2.987655\n",
      "iteration 100 / 10000: loss 1.972815\n",
      "iteration 200 / 10000: loss 1.399853\n",
      "iteration 300 / 10000: loss 1.140813\n",
      "iteration 400 / 10000: loss 0.993460\n",
      "iteration 500 / 10000: loss 0.893914\n",
      "iteration 600 / 10000: loss 0.821180\n",
      "iteration 700 / 10000: loss 0.767750\n",
      "iteration 800 / 10000: loss 0.724904\n",
      "iteration 900 / 10000: loss 0.689762\n",
      "iteration 1000 / 10000: loss 0.660427\n",
      "iteration 1100 / 10000: loss 0.634873\n",
      "iteration 1200 / 10000: loss 0.612135\n",
      "iteration 1300 / 10000: loss 0.592125\n",
      "iteration 1400 / 10000: loss 0.574676\n",
      "iteration 1500 / 10000: loss 0.558953\n",
      "iteration 1600 / 10000: loss 0.544344\n",
      "iteration 1700 / 10000: loss 0.530922\n",
      "iteration 1800 / 10000: loss 0.518835\n",
      "iteration 1900 / 10000: loss 0.507708\n",
      "iteration 2000 / 10000: loss 0.497417\n",
      "iteration 2100 / 10000: loss 0.487931\n",
      "iteration 2200 / 10000: loss 0.478963\n",
      "iteration 2300 / 10000: loss 0.470248\n",
      "iteration 2400 / 10000: loss 0.462266\n",
      "iteration 2500 / 10000: loss 0.454938\n",
      "iteration 2600 / 10000: loss 0.448152\n",
      "iteration 2700 / 10000: loss 0.441893\n",
      "iteration 2800 / 10000: loss 0.436255\n",
      "iteration 2900 / 10000: loss 0.430749\n",
      "iteration 3000 / 10000: loss 0.425476\n",
      "iteration 3100 / 10000: loss 0.420480\n",
      "iteration 3200 / 10000: loss 0.415731\n",
      "iteration 3300 / 10000: loss 0.411131\n",
      "iteration 3400 / 10000: loss 0.406801\n",
      "iteration 3500 / 10000: loss 0.402707\n",
      "iteration 3600 / 10000: loss 0.398817\n",
      "iteration 3700 / 10000: loss 0.395138\n",
      "iteration 3800 / 10000: loss 0.391732\n",
      "iteration 3900 / 10000: loss 0.388541\n",
      "iteration 4000 / 10000: loss 0.385365\n",
      "iteration 4100 / 10000: loss 0.382591\n",
      "iteration 4200 / 10000: loss 0.379609\n",
      "iteration 4300 / 10000: loss 0.376992\n",
      "iteration 4400 / 10000: loss 0.374454\n",
      "iteration 4500 / 10000: loss 0.372068\n",
      "iteration 4600 / 10000: loss 0.369857\n",
      "iteration 4700 / 10000: loss 0.367367\n",
      "iteration 4800 / 10000: loss 0.365103\n",
      "iteration 4900 / 10000: loss 0.363094\n",
      "iteration 5000 / 10000: loss 0.360660\n",
      "iteration 5100 / 10000: loss 0.358752\n",
      "iteration 5200 / 10000: loss 0.356578\n",
      "iteration 5300 / 10000: loss 0.354315\n",
      "iteration 5400 / 10000: loss 0.352363\n",
      "iteration 5500 / 10000: loss 0.350432\n",
      "iteration 5600 / 10000: loss 0.348533\n",
      "iteration 5700 / 10000: loss 0.346749\n",
      "iteration 5800 / 10000: loss 0.344983\n",
      "iteration 5900 / 10000: loss 0.343235\n",
      "iteration 6000 / 10000: loss 0.341523\n",
      "iteration 6100 / 10000: loss 0.340170\n",
      "iteration 6200 / 10000: loss 0.338206\n",
      "iteration 6300 / 10000: loss 0.336554\n",
      "iteration 6400 / 10000: loss 0.334970\n",
      "iteration 6500 / 10000: loss 0.333321\n",
      "iteration 6600 / 10000: loss 0.331829\n",
      "iteration 6700 / 10000: loss 0.330232\n",
      "iteration 6800 / 10000: loss 0.328749\n",
      "iteration 6900 / 10000: loss 0.327291\n",
      "iteration 7000 / 10000: loss 0.325888\n",
      "iteration 7100 / 10000: loss 0.324512\n",
      "iteration 7200 / 10000: loss 0.323158\n",
      "iteration 7300 / 10000: loss 0.321792\n",
      "iteration 7400 / 10000: loss 0.320500\n",
      "iteration 7500 / 10000: loss 0.319190\n",
      "iteration 7600 / 10000: loss 0.317877\n",
      "iteration 7700 / 10000: loss 0.316635\n",
      "iteration 7800 / 10000: loss 0.315326\n",
      "iteration 7900 / 10000: loss 0.314071\n",
      "iteration 8000 / 10000: loss 0.312902\n",
      "iteration 8100 / 10000: loss 0.311812\n",
      "iteration 8200 / 10000: loss 0.310447\n",
      "iteration 8300 / 10000: loss 0.309324\n",
      "iteration 8400 / 10000: loss 0.308142\n",
      "iteration 8500 / 10000: loss 0.307028\n",
      "iteration 8600 / 10000: loss 0.305956\n",
      "iteration 8700 / 10000: loss 0.304864\n",
      "iteration 8800 / 10000: loss 0.303718\n",
      "iteration 8900 / 10000: loss 0.302815\n",
      "iteration 9000 / 10000: loss 0.301699\n",
      "iteration 9100 / 10000: loss 0.300554\n",
      "iteration 9200 / 10000: loss 0.300200\n",
      "iteration 9300 / 10000: loss 0.298476\n",
      "iteration 9400 / 10000: loss 0.297502\n",
      "iteration 9500 / 10000: loss 0.296998\n",
      "iteration 9600 / 10000: loss 0.295571\n",
      "iteration 9700 / 10000: loss 0.294675\n",
      "iteration 9800 / 10000: loss 0.293693\n",
      "iteration 9900 / 10000: loss 0.292896\n",
      "Best accuracy =  0.967 when best C is 3 Best learning rate is 0.0001 Best iteration number is 10000\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# YOUR CODE HERE for testing your best model's performance                       #\n",
    "# what is the accuracy of your best model on the test set? On the training set?  #\n",
    "##################################################################################\n",
    "Best_C = 3\n",
    "svm = LinearSVM_twoclass()\n",
    "J_theta = svm.train(KK,yy,learning_rate=Best_lr,reg=Best_C,num_iters=ni,verbose=True,batch_size=KK.shape[0])\n",
    "predy = svm.predict(KKtest)\n",
    "accuracy = np.mean(predy == yy_test)\n",
    "print(\"Best accuracy = \", accuracy, \"when best C is\", Best_C, \"Best learning rate is\", Best_lr, \"Best iteration number is\", Best_ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 15 word that are predictive of spam\n",
      "our\n",
      "click\n",
      "remov\n",
      "pleas\n",
      "here\n",
      "your\n",
      "we\n",
      "receiv\n",
      "nbsp\n",
      "free\n",
      "inform\n",
      "dollarnumb\n",
      "below\n",
      "offer\n",
      "email\n",
      "top 15 word that are predictive of ham\n",
      "httpaddr\n",
      "but\n",
      "wrote\n",
      "it\n",
      "date\n",
      "user\n",
      "that\n",
      "my\n",
      "url\n",
      "thei\n",
      "there\n",
      "emailaddr\n",
      "which\n",
      "group\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# ANALYSIS OF MODEL: Print the top 15 words that are predictive of spam and for  #\n",
    "# ham. Hint: use the coefficient values of the learned model                     #\n",
    "##################################################################################\n",
    "words, inv_words = utils.get_vocab_dict()\n",
    "print(\"top 15 word that are predictive of spam\")\n",
    "XXX = np.dot(svm.theta[1:],X).argsort()\n",
    "for i in XXX[-15:][::-1]:\n",
    "    print(words[i + 1])\n",
    "print(\"top 15 word that are predictive of ham\")\n",
    "for i in XXX[:15][::1]:\n",
    "    print(words[i + 1])\n",
    "##################################################################################\n",
    "#                    END OF YOUR CODE                                            #\n",
    "##################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
